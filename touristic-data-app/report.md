# Report of Programming Project 2019/20 B2

This report summarizes the decisions taken and the work done during the development. It focuses on:

* The architecture of the application.
* How different programming techniques taught in class were applied to the project.
* The main challenges faced by each developer of the project.

This software is a student project for the *Programming Project course* at the
[Free University of Bozen-Bolzano](https://www.unibz.it/). For further details see the 
[project requirements](https://ole.unibz.it/pluginfile.php/142802/mod_resource/content/3/00_project.pdf).

## Application Architecture

The **console application** written in **Java** retrieves touristic data from the **Open Data Hub** of South Tyrol. 
Its main goal is to list touristic activities and to analyze their properties. The results are stored inside JSON
 files. Once the application has been started, no user interaction is required. Parameters are configured inside
  the `input.txt` file. Should the application be unable to complete successfully, the occurred problem is reported.  
  During normal operation, the performed steps can be listed in the following order:
  
  1. Extract data
  2. Transform data (and save touristic activities with their properties)
  3. Analyze data (and save analysis results)
  
  Data generated by the application can be found in the following directories:
  * `./results`
  * `./logs`

### Code Structure

The main class, which is the entry point of the application, is called `App` and can be found inside the package `main`.
 Following the [facade pattern](https://en.wikipedia.org/wiki/Facade_pattern), the main class is solely responsible
 for booting and stopping the application. Facade classes implement the `Task` interface, which ensures that there
  is a uniform syntax for passing control to a facade class. Currently, the application has just one facade class, but
   it is not hard to imagine how additional facades could be added. Eventually, if facades become many, the abstraction
    level can be raised further, creating a facade class that manages sub-facades.  
    The remaining classes are grouped based on their scope.

### Data Extraction

**Goal:** fetch data from the Open Data Hub according to the configuration file and make it available as `JsonNode`.  

The configuration file describing how many touristic activities should be retrieved is loaded by the class
 `UserConfig`. Http requests to fetch data from the Open Data Hub are made using **OkHttp 3**. The JSON string
  containing the fetched data is delivered by the class `OpenDataHubTourism`. This class extends `JsonFetcher` and is
   specialized for the [Activity endpoint](http://tourism.opendatahub.bz.it/api/Activity) of the Open Data Hub.

### Data Transformation

**Goal:** transform the data contained by a `JsonNode` into a set of `Activity` objects and save them into `.json` 
files.  

`ActivityDeserializer` is responsible for the deserialization and excludes duplicated data based on the Activity's ID
. `JsonSerializer` is used to serialize `Activity` objects into `.json` files. It is worth noting that
 `JsonSerializer` is able to serialize whatever object implements `JsonSerializable`. This allows us to reuse it for
  multiple scenarios. Before serializing an object, a JSON schema must be passed, which is extensively used for
   validation.

### Data Analysis

**Goal:** analyze the properties of the given `Activity` objects and save results into `.json` file.  

`ActivitiesDeserializer` delivers the results of the Analysis as one instance of `Analysis`. This is then serialized
 into a file using the previously mentioned `JsonSerializer`. After successful operation, the following information
  should be contained:
  * The activity types with their number of occurrence.
  * A list of the activities that are GPS tracked.
  * Regions with the most and the least activities.

## Programming Techniques Applied

### Advanced Object Oriented Programming

* **Interfaces:** `JsonSerializable` to ensure that for each serialized object the destination file path is known.
 `Task` to force every facade class to have the method `execute()`, which is called by the main class.

* **Generic types:** To allow `ParsingUtils#setToReadable` to process a `Set`, independent of the type of the
 elements.

* **Exception handling:** Custom exceptions to distinguish specific error cases better and make the debugging process
 easier. Uncaught exceptions are recognized by `UnexpectedExceptionHandler` and are logged as `FATAL`.

### Maven

To build, test and document the software project. Plugins were added according to the project's needs:

* maven-clean-plugin
* exec-maven-plugin
* maven-surefire-plugin
* maven-javadoc-plugin

### External Dependencies

To achieve a more efficient workflow and a more robust application, external dependecies were often used to solve
 specific tasks. This saves costs, because every feature, easy or complicated, has the potential to introduce bugs
  and is expensive to develop from scratch.
    
* mockwebserver - To test http requests offline, which is reliable and reasonably fast.
* commons-io - To delete directories.
* log4j-api & log4j-core - Log4j2 as our logging framework.
* junit-jupiter - Our testing framework for unit tests.
* jsoup - To sanitize strings removing HTML elements.
* okhttp - For HTTP requests.
* jackson-databind - To serialize and deserialize objects like `Activity` and `Analysis`.

### Regular Expressions

Since we are not in control of the backend of the Open Data Hub, we do not know all possible activity types. In
 addition, new activity types could be added without us being informed. We therefore decided to use regular
  expressions to write a more flexible JSON schema for the `Analysis` object. The applied pattern `^.*$` matches
   single line strings, regardless of the characters used inside. This gives great freedom to the syntax of
    activity types, like `activity type` and `activity.type1` being valid names.
      
### Lambda Expressions and Streams

We took advantage of lambda expressions and streams for the logic of `ActivitiesAnalyzer`. So instead of developing
 the backend logic required to process collections from scratch, we took advantage of the well-tested
  `java.util.stream.Stream` interface. This sped up the development and allowed us to achieve less error-prone code.

### Third Party Tools

We took advantage of these tools to speed up the development:

* [Postman](https://www.postman.com/) - To make HTTP requests to the Open Data Hub and visualize the response in a
   more readable way.
* [jsonschemavalidator.net](https://www.jsonschemavalidator.net) - To verify that our JSON schemas work as intended.
* [jsoneditoronline.org](https://jsoneditoronline.org) - To visualize JSON strings as a tree.
* [regex101.com](https://regex101.com/) - To write the regular expressions we needed.

## Challenges faced

#### Samuel Dalvai

1. The main challenge that I faced was to decide how the fetched JSON string would have been deserialized into an
`Activity` object. My first attempt was to use the method of the Jackson API 
`readValue(new FileReader(inputFile), Object.class)` to deserialize the JSON string directly into an `Activity`
 object. The process seemed straightforward, but for the `Activity` object to be properly deserialized, 8 additional
 classes had to be created in order to represent each subfield. In addition, this approach did not offer much
  flexibility for filtering out the data. Given these considerations, I decided to extract the required properties one
   by one, finding the various paths in the `JsonNode` and assigning them to a plain `Activity` object. In this
    way, the `Activity` class and both the serialization and the data analysis processes became much simpler. The
     structure of the `ActivityDeserializer` class ended up being more complex, but it was worth the expense.

2. Writing unit tests for the data transformation part was also quite challenging for me. To avoid IO operations as
 much as possible, I created the enum `JsonNodeExample`, which contains various JSON nodes created from scratch. This
  allowed me to have a high test coverage for different scenarios, without having to rely on file dependencies.

#### Gioele De Vitti

1. I really enjoyed using git as a version control system, but it required me to change my bad programming habits,
 which was not easy. To favour collaboration within the team, it was particularly important to make meaningful
  commits and use branches correctly.  
One of the issues I had, was that I often forgot to commit after making some changes to the code. This caused
 enormous commits that are unpleasant to manage and hard to understand for other developers. In addition, I
  struggled focusing on one single feature at a time. I used to program chaotically, jumping at will from one
   feature to another. Forcing myself to work in a feature-driven matter boosted my productivity.  
I now always try my best to write concise and informative commits, keeping in mind what my team members would
 understand when they read my commit messages. Altough this is a skill that requires further practice, I can confirm
  that I made signficant progress.

#### Filippo Cenacchi

1. My main challenge was to develop the `Analysis` class, because I had to consider how the outcoming `.json` file
 would look like after the serialization. The fields `regionsWithMostActivities` and `regionsWithLeastActivities`
  were the most complicated ones by far, because of their nested nature. The custom class `RegionsActivitiesRecord`
   solves this by containing two fields: `long numberOfActivities` and `TreeSet<String> regionIds`. The `TreeSet` was
  ideal for our needs, because it orders the IDs alphanumerically and excludes duplicates.

## Authors

Samuel Dalvai, Gioele De Vitti and Filippo Cenacchi.